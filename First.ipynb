{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q imbalanced-learn\nimport os\nimport glob\nimport cv2\nimport torch\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision.models import resnet18, ResNet18_Weights\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve\nfrom collections import Counter\nfrom imblearn.over_sampling import RandomOverSampler\n\nclass ChestXrayDataset(Dataset):\n    def __init__(self, df, root_path, transform=None):\n        self.transform = transform\n        self.all_image_paths = []\n        self.labels = []\n\n        for image_name, label in zip(df['Image Index'], df['Finding Labels']):\n            matched_paths = glob.glob(os.path.join(root_path, \"images_*/images\", image_name))\n            if matched_paths:\n                self.all_image_paths.append(matched_paths[0])\n                self.labels.append(1 if 'Cardiomegaly' in label else 0)\n\n    def __len__(self):\n        return len(self.all_image_paths)\n\n    def __getitem__(self, idx):\n        image_path = self.all_image_paths[idx]\n        label = torch.tensor(self.labels[idx]).float()\n        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# === Data Loading & Sampling ===\nbase_path = \"/kaggle/input/data\"\ndf = pd.read_csv(f\"{base_path}/Data_Entry_2017.csv\")\ndf = df[df['View Position'] == 'PA'].reset_index(drop=True)\ndf['Cardiomegaly_Label'] = df['Finding Labels'].apply(lambda x: 1 if 'Cardiomegaly' in x else 0)\n\ntrain_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['Cardiomegaly_Label'], random_state=42)\nval_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['Cardiomegaly_Label'], random_state=42)\n\n# Oversampling minority class\nros = RandomOverSampler(random_state=42)\nresampled_indices, _ = ros.fit_resample(np.arange(len(train_df)).reshape(-1, 1), train_df['Cardiomegaly_Label'])\ntrain_df = train_df.iloc[resampled_indices.flatten()]\n\n# === Transforms ===\ntrain_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485], [0.229])\n])\nval_test_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485], [0.229])\n])\n\ntrain_dataset = ChestXrayDataset(train_df, base_path, transform=train_transform)\nval_dataset = ChestXrayDataset(val_df, base_path, transform=val_test_transform)\ntest_dataset = ChestXrayDataset(test_df, base_path, transform=val_test_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device: \", device)\n\n# === Model ===\nmodel = resnet18(weights=ResNet18_Weights.DEFAULT)\nmodel.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\nmodel.fc = nn.Linear(model.fc.in_features, 1)\nmodel = model.to(device)\n\n# Weighted Loss\npos_weight = torch.tensor([\n    len(train_df[train_df.Cardiomegaly_Label == 0]) / len(train_df[train_df.Cardiomegaly_Label == 1])\n]).to(device)\n\ncriterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\noptimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)  # weight decay = L2 regularization\n\n# === Training Functions ===\ndef train_one_epoch(model, loader, optimizer, criterion):\n    model.train()\n    total_loss, correct, total = 0.0, 0, 0\n    for images, labels in loader:\n        images, labels = images.to(device), labels.to(device).unsqueeze(1)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item() * images.size(0)\n        preds = torch.sigmoid(outputs) >= 0.5\n        correct += (preds.float() == labels).sum().item()\n        total += labels.size(0)\n    return total_loss / total, correct / total\n\ndef evaluate(model, loader, criterion, threshold=0.5):\n    model.eval()\n    total_loss, correct, total = 0.0, 0, 0\n    all_labels, all_preds, all_probs = [], [], []\n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to(device), labels.to(device).unsqueeze(1)\n            outputs = model(images)\n            probs = torch.sigmoid(outputs)\n            preds = (probs >= threshold).float()\n\n            loss = criterion(outputs, labels)\n            total_loss += loss.item() * images.size(0)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(preds.cpu().numpy())\n            all_probs.extend(probs.cpu().numpy())\n    return total_loss / total, correct / total, np.array(all_labels), np.array(all_preds), np.array(all_probs)\n\n# === Train with Early Stopping ===\nnum_epochs = 20\nbest_val_loss = float('inf')\npatience = 3\npatience_counter = 0\n\nfor epoch in range(num_epochs):\n    print(f\"\\n=== Epoch {epoch+1}/{num_epochs} ===\")\n    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n    val_loss, val_acc, _, _, _ = evaluate(model, val_loader, criterion, threshold=0.5)\n\n    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n    print(f\"Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f}\")\n\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        patience_counter = 0\n        torch.save(model.state_dict(), \"/kaggle/working/cardiomegaly_resnet18.pth\")\n        print(\"âœ… Model improved and saved.\")\n    else:\n        patience_counter += 1\n        print(f\"â¸ No improvement. Patience: {patience_counter}/{patience}\")\n        if patience_counter >= patience:\n            print(\"ðŸ›‘ Early stopping triggered.\")\n            break\n\n# === Final Evaluation on Test Set ===\nmodel.load_state_dict(torch.load(\"/kaggle/working/cardiomegaly_resnet18.pth\"))\ntest_loss, test_acc, y_true, y_pred, y_prob = evaluate(model, test_loader, criterion, threshold=0.6)\n\nprint(\"\\n=== Test Results ===\")\nprint(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_true, y_pred, digits=4))\nprint(\"ROC-AUC Score:\", roc_auc_score(y_true, y_prob))\n\n# === Plot ROC & PR Curve ===\nfpr, tpr, _ = roc_curve(y_true, y_prob)\nprec, rec, _ = precision_recall_curve(y_true, y_prob)\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(fpr, tpr, label=\"ROC Curve (AUC = {:.4f})\".format(roc_auc_score(y_true, y_prob)))\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve\")\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(rec, prec, label=\"PR Curve\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision-Recall Curve\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}